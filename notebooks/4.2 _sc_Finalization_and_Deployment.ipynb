{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "6fdfa0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dash\n",
      "  Obtaining dependency information for dash from https://files.pythonhosted.org/packages/b0/68/781d0026a100106b64e4501c76621dfcd0d3c29a546094fcffaa73037a74/dash-2.16.1-py3-none-any.whl.metadata\n",
      "  Downloading dash-2.16.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: Flask<3.1,>=1.0.4 in c:\\users\\casti\\anaconda3\\lib\\site-packages (from dash) (2.2.2)\n",
      "Requirement already satisfied: Werkzeug<3.1 in c:\\users\\casti\\anaconda3\\lib\\site-packages (from dash) (2.2.3)\n",
      "Requirement already satisfied: plotly>=5.0.0 in c:\\users\\casti\\anaconda3\\lib\\site-packages (from dash) (5.9.0)\n",
      "Collecting dash-html-components==2.0.0 (from dash)\n",
      "  Obtaining dependency information for dash-html-components==2.0.0 from https://files.pythonhosted.org/packages/75/65/1b16b853844ef59b2742a7de74a598f376ac0ab581f0dcc34db294e5c90e/dash_html_components-2.0.0-py3-none-any.whl.metadata\n",
      "  Downloading dash_html_components-2.0.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting dash-core-components==2.0.0 (from dash)\n",
      "  Obtaining dependency information for dash-core-components==2.0.0 from https://files.pythonhosted.org/packages/00/9e/a29f726e84e531a36d56cff187e61d8c96d2cc253c5bcef9a7695acb7e6a/dash_core_components-2.0.0-py3-none-any.whl.metadata\n",
      "  Downloading dash_core_components-2.0.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting dash-table==5.0.0 (from dash)\n",
      "  Obtaining dependency information for dash-table==5.0.0 from https://files.pythonhosted.org/packages/da/ce/43f77dc8e7bbad02a9f88d07bf794eaf68359df756a28bb9f2f78e255bb1/dash_table-5.0.0-py3-none-any.whl.metadata\n",
      "  Downloading dash_table-5.0.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\casti\\anaconda3\\lib\\site-packages (from dash) (6.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in c:\\users\\casti\\anaconda3\\lib\\site-packages (from dash) (4.7.1)\n",
      "Requirement already satisfied: requests in c:\\users\\casti\\anaconda3\\lib\\site-packages (from dash) (2.31.0)\n",
      "Collecting retrying (from dash)\n",
      "  Obtaining dependency information for retrying from https://files.pythonhosted.org/packages/8f/04/9e36f28be4c0532c0e9207ff9dc01fb13a2b0eb036476a213b0000837d0e/retrying-1.3.4-py3-none-any.whl.metadata\n",
      "  Downloading retrying-1.3.4-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\casti\\anaconda3\\lib\\site-packages (from dash) (1.5.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\casti\\anaconda3\\lib\\site-packages (from dash) (68.0.0)\n",
      "Requirement already satisfied: Jinja2>=3.0 in c:\\users\\casti\\anaconda3\\lib\\site-packages (from Flask<3.1,>=1.0.4->dash) (3.1.2)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in c:\\users\\casti\\anaconda3\\lib\\site-packages (from Flask<3.1,>=1.0.4->dash) (2.0.1)\n",
      "Requirement already satisfied: click>=8.0 in c:\\users\\casti\\anaconda3\\lib\\site-packages (from Flask<3.1,>=1.0.4->dash) (8.0.4)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\casti\\anaconda3\\lib\\site-packages (from plotly>=5.0.0->dash) (8.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\casti\\anaconda3\\lib\\site-packages (from Werkzeug<3.1->dash) (2.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\casti\\anaconda3\\lib\\site-packages (from importlib-metadata->dash) (3.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\casti\\anaconda3\\lib\\site-packages (from requests->dash) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\casti\\anaconda3\\lib\\site-packages (from requests->dash) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\casti\\anaconda3\\lib\\site-packages (from requests->dash) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\casti\\anaconda3\\lib\\site-packages (from requests->dash) (2024.2.2)\n",
      "Requirement already satisfied: six>=1.7.0 in c:\\users\\casti\\anaconda3\\lib\\site-packages (from retrying->dash) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\casti\\anaconda3\\lib\\site-packages (from click>=8.0->Flask<3.1,>=1.0.4->dash) (0.4.6)\n",
      "Downloading dash-2.16.1-py3-none-any.whl (10.2 MB)\n",
      "   ---------------------------------------- 0.0/10.2 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/10.2 MB 9.2 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.4/10.2 MB 12.4 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 2.1/10.2 MB 15.1 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 2.8/10.2 MB 12.6 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 4.0/10.2 MB 15.0 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 4.9/10.2 MB 15.0 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 6.0/10.2 MB 15.9 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 7.2/10.2 MB 16.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 8.2/10.2 MB 16.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 9.5/10.2 MB 17.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.2/10.2 MB 17.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.2/10.2 MB 17.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.2/10.2 MB 13.9 MB/s eta 0:00:00\n",
      "Downloading dash_core_components-2.0.0-py3-none-any.whl (3.8 kB)\n",
      "Downloading dash_html_components-2.0.0-py3-none-any.whl (4.1 kB)\n",
      "Downloading dash_table-5.0.0-py3-none-any.whl (3.9 kB)\n",
      "Downloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: dash-table, dash-html-components, dash-core-components, retrying, dash\n",
      "Successfully installed dash-2.16.1 dash-core-components-2.0.0 dash-html-components-2.0.0 dash-table-5.0.0 retrying-1.3.4\n"
     ]
    }
   ],
   "source": [
    "! pip install dash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9ed89a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plotly in c:\\users\\casti\\anaconda3\\lib\\site-packages (5.9.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\casti\\anaconda3\\lib\\site-packages (from plotly) (8.2.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d66c3d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\casti\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\casti\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\casti\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "from scipy.stats import randint\n",
    "\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import WordNetLemmatizer\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "import dash\n",
    "from dash import dcc, html, Input, Output\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9728f188",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1256f18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr_vec = sp.sparse.load_npz(r'C:\\Users\\casti\\OneDrive\\Documents\\A Springboard\\Capstone 2 - Global Terrorism\\data\\interim\\X_tr_vec.npz')\n",
    "X_te_vec = sp.sparse.load_npz(r'C:\\Users\\casti\\OneDrive\\Documents\\A Springboard\\Capstone 2 - Global Terrorism\\data\\interim\\X_te_vec.npz')\n",
    "y_tr = pd.read_csv(r'C:\\Users\\casti\\OneDrive\\Documents\\A Springboard\\Capstone 2 - Global Terrorism\\data\\interim\\y_tr.csv')\n",
    "y_te = pd.read_csv(r'C:\\Users\\casti\\OneDrive\\Documents\\A Springboard\\Capstone 2 - Global Terrorism\\data\\interim\\y_te.csv')\n",
    "y_tr = y_tr.drop(columns = ['Unnamed: 0']).values.ravel()\n",
    "y_te = y_te.drop(columns = ['Unnamed: 0']).values.ravel()\n",
    "\n",
    "df1 = pd.read_csv(r'C:\\Users\\casti\\OneDrive\\Documents\\A Springboard\\Capstone 2 - Global Terrorism\\data\\interim\\dfall.csv').drop(columns=['Unnamed: 0'])\n",
    "df2 = pd.read_csv(r'C:\\Users\\casti\\OneDrive\\Documents\\A Springboard\\Capstone 2 - Global Terrorism\\data\\interim\\dfpr.csv').drop(columns=['Unnamed: 0'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93319260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['motive', 'is_weekend', 'targ_Business', 'targ_Educational Institution',\n",
      "       'targ_Government (Diplomatic)', 'targ_Government (General)',\n",
      "       'targ_Journalists & Media', 'targ_Military', 'targ_Other',\n",
      "       'targ_Police', 'targ_Private Citizens & Property',\n",
      "       'targ_Religious Figures/Institutions', 'targ_Telecommunication',\n",
      "       'targ_Terrorists/Non-State Militia', 'targ_Transportation',\n",
      "       'targ_Utilities', 'targ_Violent Political Party', 'att_Armed Assault',\n",
      "       'att_Assassination', 'att_Bombing/Explosion',\n",
      "       'att_Facility/Infrastructure Attack', 'att_Hostage Taking', 'att_Other',\n",
      "       'weap_Biological', 'weap_Chemical', 'weap_Explosives',\n",
      "       'weap_Fake Weapons', 'weap_Firearms', 'weap_Incendiary', 'weap_Melee',\n",
      "       'weap_Other', 'weap_Radiological', 'weap_Sabotage Equipment',\n",
      "       'weap_Vehicle', 'fatal_enc', 'wound_enc'],\n",
      "      dtype='object')\n",
      "       success\n",
      "0            1\n",
      "1            1\n",
      "2            1\n",
      "3            0\n",
      "4            1\n",
      "...        ...\n",
      "23759        0\n",
      "23760        1\n",
      "23761        1\n",
      "23762        1\n",
      "23763        1\n",
      "\n",
      "[23764 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "X = df1.drop(columns=['success','weap_Unknown'])\n",
    "y = df1[['success']]\n",
    "print(X.columns)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "c3e25c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['tok'] = X['motive'].apply(word_tokenize)\n",
    "wnl = WordNetLemmatizer()\n",
    "def lem_tokens(tokens) :\n",
    "    lem = [wnl.lemmatize(token) for token in tokens]\n",
    "    return ' '.join(lem)\n",
    "    \n",
    "\n",
    "X['lem'] = X.tok.apply(lem_tokens)\n",
    "X['lem']\n",
    "tv = TfidfVectorizer(ngram_range = (1,2), stop_words='english')\n",
    "tv.fit(X['lem'])\n",
    "motive_vec = tv.transform(X['lem'])\n",
    "X_num = X.drop(columns = ['motive','tok','lem']).astype(int)\n",
    "\n",
    "X_sparse = csr_matrix(X_num.values)\n",
    "\n",
    "# Concatenate sparse matrix (motive_vec) horizontally with DataFrame (X_tr)\n",
    "X_vec = hstack([X_sparse, motive_vec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "67eedbe6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23764, 100554)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a51c9234",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.drop(columns=['motive','success','weap_Unknown'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6df2be8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['is_weekend', 'targ_Business', 'targ_Educational Institution',\n",
       "       'targ_Government (Diplomatic)', 'targ_Government (General)',\n",
       "       'targ_Journalists & Media', 'targ_Military', 'targ_Other',\n",
       "       'targ_Police', 'targ_Private Citizens & Property',\n",
       "       'targ_Religious Figures/Institutions', 'targ_Telecommunication',\n",
       "       'targ_Terrorists/Non-State Militia', 'targ_Transportation',\n",
       "       'targ_Utilities', 'targ_Violent Political Party', 'att_Armed Assault',\n",
       "       'att_Assassination', 'att_Bombing/Explosion',\n",
       "       'att_Facility/Infrastructure Attack', 'att_Hostage Taking', 'att_Other',\n",
       "       'weap_Biological', 'weap_Chemical', 'weap_Explosives',\n",
       "       'weap_Fake Weapons', 'weap_Firearms', 'weap_Incendiary', 'weap_Melee',\n",
       "       'weap_Other', 'weap_Radiological', 'weap_Sabotage Equipment',\n",
       "       'weap_Vehicle', 'fatal_enc', 'wound_enc'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "1621f15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model():\n",
    "    \n",
    "    #takes whatever they input and creates a 'motive' feature\n",
    "    #creates X_te_vec for custom motive and all combinations taken from the gtd data.\n",
    "    #makes predictions of each X_te_vec and assigns labels and probabilities\n",
    "    #outputs interactive dashboard of highest probable successes and associated features\n",
    "\n",
    "    motive = input('Enter a potential suspect or affiliation and motive in your own words: ')\n",
    "\n",
    "    mot_arr = np.array([motive for i in range(len(df1))])\n",
    "    \n",
    "    feats = pd.concat([df1, pd.Series(mot_arr)], axis=1).rename(columns={0:'motive'})\n",
    "    \n",
    "    print('Tokenizing...')\n",
    "    feats['tok'] = feats['motive'].apply(lambda x: word_tokenize(x))    \n",
    "    \n",
    "    print('Lemmatizing...')\n",
    "    wnl = WordNetLemmatizer()\n",
    "    \n",
    "    def lem_tokens(tokens) :\n",
    "        lem = [wnl.lemmatize(token) for token in tokens]\n",
    "        return ' '.join(lem)\n",
    "\n",
    "    feats['lem'] = feats.tok.apply(lem_tokens)\n",
    "    \n",
    "    print('Vectorizing...')\n",
    "\n",
    "    motive_vec = tv.transform(feats['lem'])\n",
    "    \n",
    "    print('Converting to sparse matrix...')\n",
    "    feats_num = feats.drop(columns = ['motive','tok','lem']).astype(int)\n",
    "\n",
    "    feats_sparse = csr_matrix(feats_num.values)\n",
    "\n",
    "    feats_vec = hstack([feats_sparse, motive_vec])\n",
    "    \n",
    "    print('Initializing LGBM...')\n",
    "    lgbm = lgb.LGBMClassifier(objective='binary',class_weight= {0: 1.0, 1: 1.0}, n_estimators= 76)\n",
    "    \n",
    "    print('Fitting LGBM...')\n",
    "    lgbm.fit(X_vec, y.values.ravel())\n",
    "    \n",
    "    print('\\n')\n",
    "    print('Making Predictions...')\n",
    "    preds = lgbm.predict(feats_vec)\n",
    "    probs = lgbm.predict_proba(feats_vec)\n",
    "    \n",
    "    df_pr = df2\n",
    "    df_pr['prob_success'] = probs[:,1]\n",
    "    df_sort = df_pr.sort_values(by='prob_success', ascending=False)\n",
    "    \n",
    "    df_out = df_sort[['prob_success','targtype1_txt','attacktype1_txt','weaptype1_txt', 'fatalities_cat','wound_cat','is_weekend']]\n",
    "\n",
    "    print('Creating interactive dashboard...')\n",
    "    \n",
    "    \n",
    "    print('Results ready for analysis!')\n",
    "    print('\\n')\n",
    "    \n",
    "    print('Motive under investigation:')\n",
    "    print('\\n')\n",
    "    print(f'{motive}')\n",
    "    \n",
    "    threshold1 = 300\n",
    "    threshold2 = 400\n",
    "    max_thr = 8000\n",
    "    \n",
    "    \n",
    "    app = dash.Dash(__name__)\n",
    "\n",
    "    # Define the layout of the dashboard\n",
    "    app.layout = html.Div([\n",
    "    html.Div([\n",
    "        dcc.Slider(\n",
    "            id='threshold1-slider',\n",
    "            min=0,\n",
    "            max=max_thr,\n",
    "            step=100,\n",
    "            value=300,\n",
    "            marks={i: str(i) if i % 500 == 0 else '' for i in range(0, max_thr + 1, 1000)},\n",
    "            tooltip={'placement': 'bottom'}\n",
    "        ),\n",
    "        html.P(\"Target Type Value Counts Threshold\"),\n",
    "    ]),\n",
    "    html.Div([\n",
    "        dcc.Slider(\n",
    "            id='threshold2-slider',\n",
    "            min=0,\n",
    "            max=max_thr,\n",
    "            step=100,\n",
    "            value=400,\n",
    "            marks={i: str(i) if i % 500 == 0 else '' for i in range(0, max_thr + 1, 1000)},\n",
    "            tooltip={'placement': 'bottom'}\n",
    "        ),\n",
    "        html.P(\"Attack Type Value Counts Threshold\"),\n",
    "    ]),\n",
    "    html.Div([\n",
    "        dcc.Slider(\n",
    "            id='threshold3-slider',\n",
    "            min=0,\n",
    "            max=1,\n",
    "            step=0.01,\n",
    "            value=0.98,\n",
    "            marks={i/10: str(i/10) if i % 2 == 0 else '' for i in range(0, 11)},\n",
    "            tooltip={'placement': 'bottom'}\n",
    "        ),\n",
    "        html.P(\"Probability of Success Threshold\"),\n",
    "    ]),\n",
    "    dcc.Graph(id='boxplot')\n",
    "    ])\n",
    "\n",
    "    # Define callback to update the boxplot based on the threshold slider values\n",
    "    @app.callback(\n",
    "        Output('boxplot', 'figure'),\n",
    "        [\n",
    "            Input('threshold1-slider', 'value'),\n",
    "            Input('threshold2-slider', 'value'),\n",
    "            Input('threshold3-slider', 'value')\n",
    "        ]\n",
    "    )\n",
    "    def update_boxplot(threshold1, threshold2, threshold3):\n",
    "        # Filter the data based on the thresholds\n",
    "        \n",
    "        valid_rows = df_out[df_out['prob_success'] > threshold3].copy()\n",
    "        counts1 = valid_rows['targtype1_txt'].value_counts()\n",
    "        counts2 = valid_rows['attacktype1_txt'].value_counts()\n",
    "        valid_categories1 = counts1[(counts1 >= threshold1) & (counts1 <= max_thr)].index\n",
    "        valid_categories2 = counts2[(counts2 >= threshold2) & (counts2 <= max_thr)].index\n",
    "\n",
    "        df_filtered = valid_rows[\n",
    "            (df_out['targtype1_txt'].isin(valid_categories1)) &\n",
    "            (df_out['attacktype1_txt'].isin(valid_categories2))\n",
    "        ].sort_values(by='prob_success', ascending=False)\n",
    "\n",
    "        # Create the boxplot using Plotly Express\n",
    "        fig = px.box(df_filtered, x='prob_success', y='targtype1_txt', color='attacktype1_txt')\n",
    "        fig.update_layout(\n",
    "            title='Probability of Success by Target Type and Attack Type',\n",
    "            xaxis_title='Probability of Success',\n",
    "            yaxis_title='Target Type',\n",
    "            legend_title='Attack Type',\n",
    "            height=800\n",
    "        )\n",
    "\n",
    "        return fig\n",
    "            \n",
    "    # Run the app\n",
    "    if __name__ == '__main__':\n",
    "        app.run_server(debug=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d8565f",
   "metadata": {},
   "source": [
    "Sample Motives:\n",
    "\n",
    "Animal rights extremists protest university administration's decision to increase funding for animal research. Protesters are members of the \"Rights for Mice\" group.  \n",
    "\n",
    "Communist leader took power via military coup. Protesters are planning to overthrow current regime and establish a republic with an elected majority leader. \n",
    "\n",
    "Palestinian nationalists are protesting against the United States' involvement in support of the Israeli administration. Protesters are burning flags, barricading bridges, and rallying in major US cities. Tensions are high and city administrations are worried about large eruptions in protest mentality. Riot crews have already been deployed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "ffe933f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a potential suspect or affiliation and motive in your own words: Palestinian nationalists are protesting against the United States' involvement in support of the Israeli administration. Protesters are burning flags, barricading bridges, and rallying in major US cities. Tensions are high and city administrations are worried about large eruptions in protest mentality. Riot crews have already been deployed.\n",
      "Tokenizing...\n",
      "Lemmatizing...\n",
      "Vectorizing...\n",
      "Converting to sparse matrix...\n",
      "Initializing LGBM...\n",
      "Fitting LGBM...\n",
      "[LightGBM] [Info] Number of positive: 21705, number of negative: 2059\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.511022 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 83407\n",
      "[LightGBM] [Info] Number of data points in the train set: 23764, number of used features: 3134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.913356 -> initscore=2.355322\n",
      "[LightGBM] [Info] Start training from score 2.355322\n",
      "\n",
      "\n",
      "Making Predictions...\n",
      "Creating interactive dashboard...\n",
      "Results ready for analysis!\n",
      "\n",
      "\n",
      "Motive under investigation:\n",
      "\n",
      "\n",
      "Palestinian nationalists are protesting against the United States' involvement in support of the Israeli administration. Protesters are burning flags, barricading bridges, and rallying in major US cities. Tensions are high and city administrations are worried about large eruptions in protest mentality. Riot crews have already been deployed.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1b947085710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\casti\\AppData\\Local\\Temp\\ipykernel_13628\\2091197035.py:129: UserWarning:\n",
      "\n",
      "Boolean Series key will be reindexed to match DataFrame index.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabefeb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
